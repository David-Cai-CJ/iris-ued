{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from iris import RawDataset, DiffractionDataset\n",
    "import numpy as n\n",
    "from os import listdir\n",
    "from os.path import join, isdir\n",
    "from scipy.misc import imread\n",
    "from skimage.feature import register_translation\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "RESOLUTION = (2048, 2048)\n",
    "TEST_PATH = 'C:\\\\Diffraction data\\\\data_for_banff\\\\M54 20170202 to 20170508\\\\20170203 Scan03 raw data'\n",
    "OUTPUT_PATH = 'M54_scan_03.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "from os.path import join\n",
    "from os import mkdir\n",
    "\n",
    "def hdf5_to_pictures(path, output_dir):\n",
    "    \"\"\" \n",
    "    Creates a directory with averaged pictures from an iris.DiffractionDataset \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "    \n",
    "    output_dir : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_dir\n",
    "    \"\"\"\n",
    "    mkdir(output_dir)\n",
    "    dataset = DiffractionDataset(path, 'r')\n",
    "    for t in dataset.time_points:\n",
    "        imsave(join(output_dir, '{}.tiff'.format(t)), dataset.averaged_data(t))\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shift(src, shifts):\n",
    "    \"\"\" Shift an image\"\"\"\n",
    "    non = lambda s: s if s < 0 else None\n",
    "    mom = lambda s: max(0,s)\n",
    "\n",
    "    oy, ox = shifts\n",
    "\n",
    "    shifted = n.zeros_like(src)\n",
    "    shifted[mom(oy):non(oy), mom(ox):non(ox)] = src[mom(-oy):non(-oy), mom(-ox):non(-ox)]\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRawDataset(RawDataset):\n",
    "\n",
    "    resolution = RESOLUTION\n",
    "    fluence = 0\n",
    "    current = 0\n",
    "    exposure = 0\n",
    "    energy = 0\n",
    "    acquisition_date = '0.0.0.0'\n",
    "    \n",
    "    @property\n",
    "    def time_points_str(self):\n",
    "        directory = join(self.raw_directory, listdir(self.raw_directory)[0])\n",
    "        files = filter(lambda p: p.endswith('.png'), listdir(directory))\n",
    "        indices = map(lambda p: str(p).split('_')[0], files)\n",
    "        return list(filter(lambda i: int(i)%2 == 1, indices))\n",
    "    \n",
    "    @property\n",
    "    def time_points(self):\n",
    "        return list(map(float, self.time_points_str))\n",
    "    \n",
    "    @property\n",
    "    def nscans(self):   \n",
    "        potentials = [join(self.raw_directory, p) for p in listdir(self.raw_directory) if isdir(join(self.raw_directory, p))]\n",
    "        return list(range(len(potentials)))\n",
    "\n",
    "    def process(self, filename, callback = print):\n",
    "        \"\"\"\n",
    "        Processes raw data into something useable by iris.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str {*.hdf5}\n",
    "            Filename for the DiffractionDataset object\n",
    "        compression : str, optional\n",
    "\n",
    "        callback : callable or None, optional\n",
    "            Callable with one argument executed at the end of each time-delay processing.\n",
    "            Argument will be the progress as an integer between 0 and 100.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        path\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare compression kwargs\n",
    "        ckwargs = {'compression' : 'lzf', 'chunks' : True, 'shuffle' : True, 'fletcher32' : True}\n",
    "        \n",
    "        with DiffractionDataset(name = filename, mode = 'w') as processed:\n",
    "\n",
    "            # Copy experimental parameters\n",
    "            # Center and beamblock_rect will be modified\n",
    "            # because of reduced resolution later\n",
    "            processed.nscans = self.nscans\n",
    "            processed.time_points = self.time_points\n",
    "            processed.acquisition_date = self.acquisition_date\n",
    "            processed.fluence = self.fluence\n",
    "            processed.current = self.current\n",
    "            processed.exposure = self.exposure\n",
    "            processed.energy = self.energy\n",
    "            processed.resolution = self.resolution\n",
    "            processed.sample_type = 'single_crystal'\n",
    "            processed.center = (0,0)\n",
    "            processed.beamblock_rect = (0,0,0,0)\n",
    "\n",
    "        # Preallocation\n",
    "        # The following arrays might be resized if there are missing pictures\n",
    "        # but preventing copying can save about 10%\n",
    "        cube = n.ma.empty(shape = self.resolution + (len(self.nscans),), dtype = n.int32, fill_value = 0.0)\n",
    "        absdiff = n.ma.empty_like(cube, dtype = n.float32)\n",
    "        int_intensities = n.empty(shape = (1,1,len(self.nscans)), dtype = n.float32)\n",
    "        averaged = n.ma.empty(shape = self.resolution, dtype = n.float32)\n",
    "        mad = n.ma.empty(shape = self.resolution + (1,), dtype = n.float32)\n",
    "\n",
    "        data_dirs = list(map(lambda p: join(self.raw_directory, p), listdir(self.raw_directory)))\n",
    "        data_dirs = list(filter(lambda d: 'average' not in d, data_dirs))\n",
    "\n",
    "        for i, timedelay in tqdm(enumerate(self.time_points_str)):\n",
    "        \n",
    "            slice_index = 0\n",
    "            # Define the first scan as the reference for translations\n",
    "            for scan in self.nscans:\n",
    "                \n",
    "                directory = [join(self.raw_directory, p) \n",
    "                             for p in listdir(self.raw_directory) \n",
    "                             if isdir(join(self.raw_directory, p))][scan]\n",
    "                imf = join(directory, next(filter(lambda f: f.startswith(timedelay.zfill(3)), \n",
    "                                                  listdir(directory))))\n",
    "                if slice_index == 0:\n",
    "                    ref_im = imread(imf, mode = 'I')\n",
    "                    cube[:,:,0] = ref_im\n",
    "                else:\n",
    "                    im = imread(imf, mode = 'I')\n",
    "                    shifts, *_ = register_translation(ref_im, im, 1, space = 'real')\n",
    "                    cube[:,:,slice_index] =  shift(im, shifts)\n",
    "                slice_index += 1\n",
    "            \n",
    "            # Mask outliers according to the median-absolute-difference criterion\n",
    "            # Consistency constant of 1.4826 due to underlying normal distribution\n",
    "            # http://eurekastatistics.com/using-the-median-absolute-deviation-to-find-outliers/\n",
    "            n.ma.abs(cube - n.ma.median(cube, axis = 2, keepdims = True), out = absdiff)\n",
    "            mad[:] = 1.4826*n.ma.median(absdiff, axis = 2, keepdims = True)     # out = mad bug with keepdims = True\n",
    "            cube[absdiff > 3*mad] = n.ma.masked\n",
    "\n",
    "            # Normalize data cube intensity\n",
    "            # Integrated intensities are computed for each \"picture\" (each slice in axes (0, 1))\n",
    "            # Then, the data cube is normalized such that each slice has the same integrated intensity\n",
    "            n.ma.sum(n.ma.sum(cube, axis = 0, keepdims = True, dtype = n.float32), axis = 1, keepdims = True, dtype = n.float32, out = int_intensities)\n",
    "            int_intensities /= n.ma.mean(int_intensities)\n",
    "            averaged[:] = n.ma.mean(cube / int_intensities, axis = 2) # out = averaged bug\n",
    "\n",
    "            with DiffractionDataset(name = filename, mode = 'r+') as processed:\n",
    "                gp = processed.processed_measurements_group.create_group(name = str(float(timedelay)))\n",
    "                gp.create_dataset(name = 'intensity', data = n.ma.filled(averaged, 0), dtype = n.float32, **ckwargs)\n",
    "                gp.create_dataset(name = 'error', data = n.zeros(RESOLUTION), dtype = n.float32, **ckwargs)\n",
    "            \n",
    "            callback(round(100*i / len(self.time_points)))\n",
    "\n",
    "        callback(100)\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = SRawDataset(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\IntelPython35\\lib\\site-packages\\ipykernel\\__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "16it [31:25, 117.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M54_scan_03.hdf5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.process(OUTPUT_PATH, callback = lambda x: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 3.0, 5.0, 7.0, 9.0, 11.0, 13.0, 15.0, 17.0, 19.0, 21.0, 23.0, 25.0, 27.0, 29.0, 31.0)\n"
     ]
    }
   ],
   "source": [
    "d = DiffractionDataset(OUTPUT_PATH)\n",
    "print(d.time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M54_scan_03'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_to_pictures(OUTPUT_PATH, 'M54_scan_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
